{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msqlalchemy\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m create_engine\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdatetime\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m datetime\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/taxi-chicago-etl-4NUiHc4V-py3.12/lib/python3.12/site-packages/pandas/__init__.py:14\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _dependency \u001b[38;5;129;01min\u001b[39;00m _hard_dependencies:\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 14\u001b[0m         \u001b[38;5;28;43m__import__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m_dependency\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m _e:  \u001b[38;5;66;03m# pragma: no cover\u001b[39;00m\n\u001b[1;32m     16\u001b[0m         _missing_dependencies\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m_dependency\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m_e\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/taxi-chicago-etl-4NUiHc4V-py3.12/lib/python3.12/site-packages/numpy/__init__.py:130\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _distributor_init\n\u001b[1;32m    129\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 130\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m__config__\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m show \u001b[38;5;28;01mas\u001b[39;00m show_config\n\u001b[1;32m    131\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    132\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\"\"\u001b[39m\u001b[38;5;124mError importing numpy: you should not try to import numpy from\u001b[39m\n\u001b[1;32m    133\u001b[0m \u001b[38;5;124m    its source directory; please exit the numpy source tree, and relaunch\u001b[39m\n\u001b[1;32m    134\u001b[0m \u001b[38;5;124m    your python interpreter from there.\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/taxi-chicago-etl-4NUiHc4V-py3.12/lib/python3.12/site-packages/numpy/__config__.py:4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# This file is generated by numpy's build process\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# It contains system_info results at the time of building this package.\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01menum\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Enum\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_multiarray_umath\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m      5\u001b[0m     __cpu_features__,\n\u001b[1;32m      6\u001b[0m     __cpu_baseline__,\n\u001b[1;32m      7\u001b[0m     __cpu_dispatch__,\n\u001b[1;32m      8\u001b[0m )\n\u001b[1;32m     10\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshow\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     11\u001b[0m _built_with_meson \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/taxi-chicago-etl-4NUiHc4V-py3.12/lib/python3.12/site-packages/numpy/core/__init__.py:24\u001b[0m\n\u001b[1;32m     21\u001b[0m         env_added\u001b[38;5;241m.\u001b[39mappend(envkey)\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 24\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m multiarray\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msys\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/taxi-chicago-etl-4NUiHc4V-py3.12/lib/python3.12/site-packages/numpy/core/multiarray.py:10\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;124;03mCreate the numpy.core.multiarray namespace for backward compatibility. In v1.16\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03mthe multiarray and umath c-extension modules were merged into a single\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      6\u001b[0m \n\u001b[1;32m      7\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mfunctools\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m overrides\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _multiarray_umath\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_multiarray_umath\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m  \u001b[38;5;66;03m# noqa: F403\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/taxi-chicago-etl-4NUiHc4V-py3.12/lib/python3.12/site-packages/numpy/core/overrides.py:8\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m set_module\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_utils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_inspect\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m getargspec\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_multiarray_umath\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m      9\u001b[0m     add_docstring,  _get_implementing_args, _ArrayFunctionDispatcher)\n\u001b[1;32m     12\u001b[0m ARRAY_FUNCTIONS \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n\u001b[1;32m     14\u001b[0m array_function_like_doc \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     15\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"like : array_like, optional\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;124;03m        Reference object to allow the creation of arrays which are not\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;124;03m        compatible with that passed in via this argument.\"\"\"\u001b[39;00m\n\u001b[1;32m     21\u001b[0m )\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:463\u001b[0m, in \u001b[0;36m_lock_unlock_module\u001b[0;34m(name)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "from datetime import datetime\n",
    "\n",
    "DATASET_FILEPATH = 'Taxi_Chicago.csv'\n",
    "df = pd.read_csv(DATASET_FILEPATH)\n",
    "df = df[~df['Taxi ID'].isnull()]\n",
    "\n",
    "server = 'DESKTOP-HFN3ITE'\n",
    "database = 'TaxiTrips'\n",
    "username = 'user1'\n",
    "password = 'sa'\n",
    "driver = 'ODBC Driver 17 for SQL Server'\n",
    "connection_string = f'mssql+pyodbc://{username}:{password}@{server}/{database}?driver={driver}'\n",
    "engine = create_engine(connection_string)\n",
    "\n",
    "df['ID_TaxiT'] = pd.factorize(df['Taxi ID'])[0] + 1\n",
    "taxi_table = df[['ID_TaxiT', 'Taxi ID']].drop_duplicates().rename(columns={'Taxi ID': 'HashIDTaxi'})\n",
    "taxi_table.set_index('ID_TaxiT', inplace=True)\n",
    "taxi_table.to_sql('Taxi', con=engine, schema='stageProjectIDH', if_exists='append', index=True)\n",
    "\n",
    "df['ID_PaymentTypeT'] = pd.factorize(df['Payment Type'])[0] + 1\n",
    "payment_type_table = df[['ID_PaymentTypeT', 'Payment Type']].drop_duplicates().rename(columns={'Payment Type': 'Title'})\n",
    "payment_type_table.set_index('ID_PaymentTypeT', inplace=True)\n",
    "payment_type_table.to_sql('PaymentType', con=engine, schema='stageProjectIDH', if_exists='append', index=True)\n",
    "\n",
    "df['ID_CompanyT'] = pd.factorize(df['Company'])[0] + 1\n",
    "company_table = df[['ID_CompanyT', 'Company']].drop_duplicates().rename(columns={'Company': 'Title'})\n",
    "company_table.set_index('ID_CompanyT', inplace=True)\n",
    "company_table.to_sql('Company', con=engine, schema='stageProjectIDH', if_exists='append', index=True)\n",
    "\n",
    "def normalize_timestamps(df, column_name):\n",
    "    timestamp_fields = df[column_name].apply(lambda x: datetime.strptime(x, '%m/%d/%Y %I:%M:%S %p'))\n",
    "    timestamp_table = pd.DataFrame({\n",
    "        'ID_TimestampT': pd.factorize(df[column_name].astype(str))[0] + 1,\n",
    "        'Year': timestamp_fields.dt.year,\n",
    "        'Month': timestamp_fields.dt.month,\n",
    "        'Day': timestamp_fields.dt.day,\n",
    "        'Hour': timestamp_fields.dt.hour,\n",
    "        'Minute': timestamp_fields.dt.minute,\n",
    "        'Second': timestamp_fields.dt.second\n",
    "    }).drop_duplicates()\n",
    "    timestamp_table.set_index('ID_TimestampT', inplace=True)\n",
    "    return timestamp_table\n",
    "\n",
    "pickup_timestamps = normalize_timestamps(df, 'Trip Start Timestamp')\n",
    "pickup_timestamps.to_sql('TimestampT', con=engine, schema='stageProjectIDH', if_exists='append', index=False)\n",
    "\n",
    "dropoff_timestamps = normalize_timestamps(df, 'Trip End Timestamp')\n",
    "dropoff_timestamps.to_sql('TimestampT', con=engine, schema='stageProjectIDH', if_exists='append', index=False)\n",
    "\n",
    "all_timestamps = pd.concat([pickup_timestamps, dropoff_timestamps]).drop_duplicates().reset_index(drop=True)\n",
    "all_timestamps.to_sql('TimestampT', con=engine, schema='stageProjectIDH', if_exists='append', index=False)\n",
    "\n",
    "def normalize_areas(df, column_name):\n",
    "    area_table = pd.DataFrame({\n",
    "        'ID_CommunityAreaT': pd.factorize(df[column_name])[0] + 1,\n",
    "        'IdentifierArea': df[column_name]\n",
    "    })\n",
    "    area_table.set_index('ID_CommunityAreaT', inplace=True)\n",
    "    return area_table\n",
    "\n",
    "pickup_areas = normalize_areas(df, 'Pickup Community Area')\n",
    "pickup_areas.to_sql('CommunityArea', con=engine, schema='stageProjectIDH', if_exists='append', index=False)\n",
    "\n",
    "dropoff_areas = normalize_areas(df, 'Dropoff Community Area')\n",
    "dropoff_areas.to_sql('CommunityArea', con=engine, schema='stageProjectIDH', if_exists='append', index=False)\n",
    "\n",
    "all_areas = pd.concat([pickup_areas, dropoff_areas]).drop_duplicates().reset_index(drop=True)\n",
    "all_areas.to_sql('CommunityArea', con=engine, schema='stageProjectIDH', if_exists='append', index=False)\n",
    "\n",
    "def normalize_tracts(df, column_name):\n",
    "    tract_table = pd.DataFrame({\n",
    "        'ID_CensusTractT': pd.factorize(df[column_name])[0] + 1,\n",
    "        'IdentifierCensusTract': df[column_name]\n",
    "    })\n",
    "    tract_table.set_index('ID_CommunityAreaT', inplace=True)\n",
    "    return tract_table\n",
    "    tracts = df[column_name].dropna().drop_duplicates().astype(int).reset_index(drop=True)\n",
    "    tract_table = pd.DataFrame(tracts)\n",
    "    tract_table['ID_CensusTractT'] = tract_table.index + 1\n",
    "    tract_table.columns = ['IdentifierCensusTract', 'ID_CensusTractT']\n",
    "    return tract_table\n",
    "\n",
    "pickup_tracts = normalize_tracts(df, 'Pickup Census Tract')\n",
    "pickup_tracts.to_sql('CensusTract', con=engine, schema='stageProjectIDH', if_exists='append', index=False)\n",
    "\n",
    "dropoff_tracts = normalize_tracts(df, 'Dropoff Census Tract')\n",
    "dropoff_tracts.to_sql('CensusTract', con=engine, schema='stageProjectIDH', if_exists='append', index=False)\n",
    "\n",
    "# Combine and deduplicate census tracts\n",
    "all_tracts = pd.concat([pickup_tracts, dropoff_tracts]).drop_duplicates().reset_index(drop=True)\n",
    "all_tracts.to_sql('CensusTract', con=engine, schema='stageProjectIDH', if_exists='append', index=False)\n",
    "\n",
    "# Insert data for Trip\n",
    "# Map the normalized IDs to the Trip table\n",
    "df = df.merge(all_timestamps, left_on='Trip Start Timestamp', right_on='Timestamp', how='left')\n",
    "df = df.merge(all_timestamps, left_on='Trip End Timestamp', right_on='Timestamp', how='left', suffixes=('_Start', '_End'))\n",
    "df = df.merge(all_areas, left_on='Pickup Community Area', right_on='IdentifierArea', how='left')\n",
    "df = df.merge(all_areas, left_on='Dropoff Community Area', right_on='IdentifierArea', how='left', suffixes=('_Pickup', '_Dropoff'))\n",
    "df = df.merge(all_tracts, left_on='Pickup Census Tract', right_on='IdentifierCensusTract', how='left')\n",
    "df = df.merge(all_tracts, left_on='Dropoff Census Tract', right_on='IdentifierCensusTract', how='left', suffixes=('_Pickup', '_Dropoff'))\n",
    "\n",
    "# Prepare the Trip table data\n",
    "trip_table = df.rename(columns={\n",
    "    'Trip ID': 'IdentifierTrip',\n",
    "    'Trip Seconds': 'Seconds',\n",
    "    'Trip Miles': 'Miles',\n",
    "    'Fare': 'Fares',\n",
    "    'Trip Total': 'Total',\n",
    "    # Add the ID mappings\n",
    "    'ID_TimestampT_Start': 'StartTimestampID',\n",
    "    'ID_TimestampT_End': 'EndTimestampID',\n",
    "    'ID_CommunityAreaT_Pickup': 'PickupCommunityAreaID',\n",
    "    'ID_CommunityAreaT_Dropoff': 'DropoffCommunityAreaID',\n",
    "    'ID_CensusTractT_Pickup': 'PickupCensusTractID',\n",
    "    'ID_CensusTractT_Dropoff': 'DropoffCensusTractID'\n",
    "}).drop(columns=['Taxi ID', 'Payment Type', 'Company', 'Trip Start Timestamp', 'Trip End Timestamp', 'Pickup Community Area', 'Dropoff Community Area', 'Pickup Census Tract', 'Dropoff Census Tract', 'Timestamp', 'IdentifierArea', 'IdentifierCensusTract'])  # Drop redundant columns after ID mapping\n",
    "trip_table['ID_Trip'] = pd.factorize(trip_table['IdentifierTrip'])[0] + 1\n",
    "trip_table.to_sql('Trip', con=engine, schema='stageProjectIDH', if_exists='append', index=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
